############################################################
####
#####由higahsi生成的原始的稀疏矩阵生成prebulk数据及bed文件作为dchic的输入
#####
##########################################################
#############################################################
#############################################################
##################################################################
##################################################################
from Higashi_backend.utils import *
from Higashi_analysis.Higashi_analysis import *
import h5py
from sklearn.preprocessing import MinMaxScaler, quantile_transform
import os

os.environ["OMP_NUM_THREADS"] = "10"
import pandas as pd
import argparse
import scipy.sparse
from scipy.sparse import hstack,vstack
import math

config=get_config('/home/python/higashi/dataset2/cortex_250k_tmp/config_cellcycle.json')
res = config['resolution']
data_dir = config['data_dir']
temp_dir = config['temp_dir']
raw_dir = os.path.join(temp_dir, "raw")
if 'cytoband_path' in config:
	cytoband_path = config['cytoband_path']
else:
	cytoband_path = None
neighbor_num = config['neighbor_num']
embedding_name = config['embedding_name']

chrom_list = config['impute_list']
# chrom_list = ['chr1', 'chr2']
chrom_list = np.array(chrom_list)


################从基因组参考文件计算一定分辨率下各染色体bin的数量
def create_bed(res):

    file_path = '/home/python/higashi/dataset2/cortex/config/mm10.chrom.sizes.txt'  
    with open(file_path, 'r') as file:
        lines = file.readlines()
    chromosome_bins = {}
    max_lens = {}
    # 特定分辨率
    resolution = res # 请替换成你的分辨率
    # 遍历文件中的每一行
    for line in lines:
        # 分割每一行的染色体和对应的长度
        chromosome, length = line.strip().split('\t')
        
        # 计算染色体对应的bin数量
        # bin_count = int(length) // resolution
        bin_count = math.ceil(int(length) / resolution)
        
        # 存储结果到字典中
        chromosome_bins[chromosome] = bin_count
        max_lens[chromosome] = int(length)
    bin_chrom_list = []
    bin_start_list = []
    bin_end_list = []
    for chrom in chromosome_bins:
        bin_count = chromosome_bins[chrom]
        bin_chrom_list+=[chrom]*bin_count
        bin_start_list.extend((np.arange(bin_count) * res))
        end=(np.arange(bin_count) + 1) * res
        # print(len(end))
        max_len=max_lens[chromosome]
        end[bin_count-1]=max_len
        # bin_end_list.extend(((np.arange(bin_count) + 1) * res))
        bin_end_list.extend(end)
        # print (chrom, "finished")
        # print(chrom)
        # print(bin_count)
    index_list=np.arange(1,len(bin_chrom_list)+1)
    df=pd.DataFrame()
    df['chr']=bin_chrom_list
    df['start']=bin_start_list
    df['end']=bin_end_list
    df['index']=index_list
    bed_path='test_bed.bed'
    df.to_csv(bed_path, sep='\t', index=None, header=False, mode='w')
    print(f"bed file written to {bed_path}")
    return chromosome_bins


def process_chrom(chrom,cell_type):
# Get the raw sparse mtx list
    origin_sparse = np.load(os.path.join(raw_dir, "%s_sparse_adj.npy" % chrom), allow_pickle=True)
    size = origin_sparse[0].shape[0]
    pre_bulk_list=[]
    # sum_by_label=[]
    a={}
    b={}
    # c={}
    for j in list(set(cell_type)):
        # print(j)
        indices = [index for index, value in enumerate(cell_type) if value == j]
        a[j]=indices
        b[j] = np.zeros_like(np.array(origin_sparse[0]))
        for i in a[j]:
            proba = np.array(origin_sparse[i])    
            b[j] +=proba
        temp = np.array(b[j].item().todense())
        temp=scipy.sparse.csr_matrix(temp)
            # temp = b[j]
        pre_bulk_list.append(temp)
    return pre_bulk_list

from tqdm import tqdm
output_dir='/home/python/higashi/dcpc/cortex_prebulk_from_sc_with_rep'
print('chrom_list:',chrom_list)
# with open('matrix_values.txt', 'w') as file:
# cell_type_info=pickle.load(open(os.path.join(data_dir, "label_info.pickle"), "rb"))
#使用重复样本标签

cell_type_info=pickle.load(open('/home/python/higashi/notebook/cortex_label_info.pickle', "rb"))
cell_type=cell_type_info['cell_type']
cell_type_list=[]
chromosome_bins=create_bed(res)
for j in list(set(cell_type)):
    cell_type_list.append(j)
bin_count=0
pre_bulk_raw=[]
for chrom in chrom_list:
    pre_bulk_list=process_chrom(chrom,cell_type)
    print (chrom, "finished")
    pre_bulk_list_unzip=[]
    for bulk in pre_bulk_list:
        rows, cols, values = scipy.sparse.find(bulk)
        rows+=bin_count
        cols+=bin_count
        pre_bulk_list_unzip.append([cols,rows,values])
        # pre_bulk_list_unzip.append(rows)
        # pre_bulk_list_unzip.append(values)
        # bulk.nonzero().row+=bin_count
        # bulk.nonzero().col+=bin_count
    bin_count += chromosome_bins[chrom] 
    pre_bulk_raw.append(pre_bulk_list_unzip)
temp_bulk ={}
for i in tqdm(range(len(pre_bulk_raw[0]))):
    sample_name=cell_type_list[i]+'.matrix'
    save_path=os.path.join(output_dir, sample_name)
    # save_path=cell_type_list[i]+'_prebulk_mat.txt'   
    temp_bulk[i]=[]
    for j in range(len(pre_bulk_raw)):
        # print('j,i',j,i)
        temp_bulk[i].append(pre_bulk_raw[j][i])
    temp_bulk[i]=np.column_stack([np.vstack(group) for group in temp_bulk[i]])
    np.savetxt(save_path, temp_bulk[i].T, delimiter='\t', fmt='%d')
    print(f"Data written to {save_path}")
